{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3b6da5a6076d16b0a680620585ed0db8f283376460b9dbd6925dbd4d8b89dcd2"
   }
  },
  "interpreter": {
   "hash": "3b6da5a6076d16b0a680620585ed0db8f283376460b9dbd6925dbd4d8b89dcd2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Running pcarpet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "# import pcarpet\n",
    "pcarpet_path = os.path.join(os.path.dirname(os.getcwd()), 'pcarpet')\n",
    "sys.path.insert(0, pcarpet_path)\n",
    "import pcarpet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initializing pcarpet\n",
    "`pcarpet` needs 3 paths to be specified:\n",
    "\n",
    "1. fMRI file: a 4d nifti file containing the preprocessed fMRI data\n",
    "2. Mask file: a 3d nifti file, containing a binary mask that defines a single region-of-interest (e.g. cortex)\n",
    "3. Output folder: for storing the outputs generated by pcarpet\n",
    "   \n",
    "The fMRI and Mask files need to be in the same space, with identical x-y-z dimensions. For example, they can both be in the native anatomical space of the subject, or in a template space to which the data have been resampled."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Folder containing example data\n",
    "example_folder = '/home/niko/MRI/pcarpet_example/macaque'\n",
    "\n",
    "# 1. Path to preprocessed fMRI file\n",
    "func = os.path.join(example_folder, 'func_preproc.nii.gz')\n",
    "# 2. Path to a cortical mask\n",
    "cortex_mask = os.path.join(example_folder, 'cortex_mask.nii.gz')\n",
    "# 3. Path to a folder for storing the outputs\n",
    "output_folder = os.path.join(example_folder, 'outputs')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To initialize pcarpet, we first create `Dataset` object, using the three paths from above"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "MyData = pcarpet.Dataset(func, cortex_mask, output_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Initialized Dataset object:\n",
      "\tfMRI file: /home/niko/MRI/pcarpet_example/macaque/func_preproc.nii.gz\n",
      "\tMask file: /home/niko/MRI/pcarpet_example/macaque/cortex_mask.nii.gz\n",
      "\tOutput directory: /home/niko/MRI/pcarpet_example/macaque/outputs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the `Dataset` object is created, we have two ways of running the `pcarpet` pipeline on it:\n",
    "\n",
    "1. Running the entire pipeline at once\n",
    "2. Running the pipeline step-by-step\n",
    "   \n",
    "Below, we will first demonstrate the convenient first option. We will then go through the step-by-step option, which may be useful for debugging and for understanding the vairous inputs and outputs of the pipeline."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option 1: Running the entire pcarpet pipeline at once\n",
    "We can directly call the `run_pcarpet` method of the `Dataset` object, which will execute the pipeline with default options."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "MyData.run_pcarpet()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading data...\n",
      "\tfMRI data read: dimensions (80, 33, 80, 600)\n",
      "\tMask read: dimensions (80, 33, 80)\n",
      "fMRI data reshaped to voxels x time (211200, 600).\n",
      "21589 voxels retained after masking.\n",
      "Carpet matrix created with shape (21589, 600).\n",
      "Carpet normalized to zero-mean unit-variance.\n",
      "Carpet reordered.\n",
      "PCA fit to carpet and results saved.\n",
      "First 5 PCs correlated with carpet.\n",
      "Out of these, 3 sign-flipped.\n",
      "First 5 PCs correlated with fMRI data.\n",
      "TR of 2.000 seconds read from fMRI header\n",
      "Visual report generated and saved as First5_PCs_carpet_corr_report.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see what the default options were, since they are stored in a dictionary called `used_options`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ops = MyData.used_options\n",
    "for key, val in ops.items():\n",
    "    print(f'{key}: {val}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tSNR_thresh: 15.0\n",
      "reorder_carpet: True\n",
      "save_carpet: False\n",
      "save_pca_scores: False\n",
      "ncomp: 5\n",
      "flip_sign: True\n",
      "TR: auto\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Any of the above default options can be overriden by explicitly passing them as arguments to the `run_pcarpet` call. For example: \n",
    "\n",
    "```python\n",
    "MyData.run_pcarpet(tSNR_thesh=10, reorder_carpet=False)\n",
    "```\n",
    "\n",
    "The meaning of each of these option will become clear in the step-by-step guide that follows."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option 2: Running pcarpet step-by-step\n",
    "### Step 1: Importing the data\n",
    "The first function, `import_data`, uses the `nibabel` package to import the fMRI data and the Mask into python as numpy arrays, and stores them as object attributes `data` and `mask`, respectiveyl. It also stores other attributes, like the x-y-z-t dimensions of fMRI data, the nifti header and the affine matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "MyData.import_data()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading data...\n",
      "\tfMRI data read: dimensions (80, 33, 80, 600)\n",
      "\tMask read: dimensions (80, 33, 80)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Getting the carpet\n",
    "The second function, `get_carpet`, generates a 'carpet' from the fMRI data and the mask. A carpet is a 2d matrix, shaped voxels x time, which contains the normalized (z-score) BOLD-fMRI signal from within the mask.\n",
    "\n",
    "The fMRI data is first reshaped to 2d. Voxels that are outside the mask as well as voxels below a specified temporal signal-to-noise ratio threshold `tSNR_thresh` (default = 15) are discarded. The retained voxels are tranformed into 2d and normalized through z-scoring (subtract mean and divide by standard deviation along the time dimension).\n",
    "\n",
    "By default, the rows of the carpet matrix (voxels) are ordered according to their (decreasing) correlation with the global (mean across voxels) signal. The reordering helps to highlight widespread signal fluctuations. It can be turned off by setting the `reorder_carpet` argument to `False`.\n",
    "\n",
    "The carpet matrix is stored as a `carpet` attribute of the `Dataset` object. Optionally, it can be written to the output folder as a `carpet.npy` file (can be large), by setting the `save_carpet` argument to `True`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "MyData.get_carpet(tSNR_thresh=15.0,\n",
    "                  reorder_carpet=True, save_carpet=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fMRI data reshaped to voxels x time (211200, 600).\n",
      "21589 voxels retained after masking.\n",
      "Carpet matrix created with shape (21589, 600).\n",
      "Carpet normalized to zero-mean unit-variance.\n",
      "Carpet reordered.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Fit PCA to carpet\n",
    "The third function, `fit_pca2carpet`, fits PCA to the `carpet` matrix and saves the principal componens (PCs), the explained variance ratios, and optionally the PCA scores (PCA-tranformed carpet). \n",
    "\n",
    "The PCs are stored as a `pca_comps` attribute of the `Dataset` object and are also written to the output folder as a `PCs_all.npy` file. \n",
    "\n",
    "The explained variance ratios per PC are stored as a `expl_var` attribute of the `Dataset` object and are also written to the output folder as a `PCs_all_expl_variance_ratio.npy` file.\n",
    "\n",
    "If the `save_pca_scores` option is set to `True`, the PCA-transformed data will be written to the output folder as a `PCA_scores_all.npy` file (will be large)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "MyData.fit_pca2carpet(save_pca_scores=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PCA fit to carpet and results saved.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}